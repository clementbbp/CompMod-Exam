---
title: "Information Integration Project"
author: "Clement Peters"
date: "5/1/2021"
output: html_document
---

#Loading Packages
```{r}
##Packages
pacman::p_load(tidyverse, stringr, dplyr, brms, bayesplot,
               loo,
               lme4)
```

#Defining functions:
```{r}

Integrate_main <- function(Agents, i, Info){
  
  # #If true, check if memory is full
         for(j in 10:ncol(Agents)){

        #Check if memory slot is open
         if(Agents[i,j] == 0){
           j <- as.numeric(j)

           #If true, save the information to the empty memory space
           Agents[i,j] <- Info$xi[1]
           Agents[i,(j+1)] <- Info$yi[1]

            #Break out of loop and continue to next agent
            break
         }
           
        }
  
        #If full, sample memory space, and replace with new value (integrate)
        
        #which place in memory should the new info go
        
        #Sample which memory should be replaced. There are nMemo possible values
        sample_num <- as.character(sample(1:((ncol(Agents)-9)/2), size=1)) 
        
        #Now i have the location (sample_num), I just need to plot in the new                   information
        colnames_df <- colnames(Agents[i,])
       
        memory_to_replace <- as.data.frame(str_detect(colnames_df, sample_num))
        
        #Now I know the columns in which the new info should go. So I need to put it there
        column <- numeric()
        for(k in 1:nrow(memory_to_replace)){
          if(memory_to_replace[k,] == TRUE){
            k <- as.numeric(k)
            column <- c(column, k) # Saving the index of the columns
            #column <- as.list(column)
            
          }
        }
        x_coord <- column[[1]] # memory x coordinate column number
        y_coord <- column[[2]] # memory y coordinate column number
        
        # And now we save the new memory in the right location
        Agents[i,][,x_coord] <- Info$xi[1]
        Agents[i,][,y_coord] <- Info$yi[1]
        
        #Now memory is updated. Time to update location on attitude space
        
        #First reset agent position to 0 before updating memory
        Agents$x[i] <- 0
        Agents$y[i] <- 0
        
        #Because the location of the agent is dependent on its memory, it will always be zero to begin with because almost all memories are "neutral". I need to average only over the non-zero memories.
        
        #Number of non-zero columns per agent a.k.a. how many memory spaces are filled + other variables
        
         nonZero <- sum(apply(Agents[i,], 2, function(c)sum(c!=0)))
         nonZero <- as.numeric(nonZero)
        
        # Averaging the x-values over the number of memories (of value x)
        Agents$x[i] <-  (sum(Agents[i,seq(10, ncol(Agents), 2)])/((nonZero-7)/2)) # -9 because there are always those 9 non memory columns which are nonZero, assuming that x and y are non zero.
        
        # Averaging the y-values over the number of memories (of value y)
        Agents$y[i] <- (sum(Agents[i,seq(11, ncol(Agents), 2)])/((nonZero-7)/2)) 
       return(Agents)
      }

Integrate_social <- function(Agents, Social_group, s, Info){
  
  # #If true, check if memory is full
         for(v in 10:ncol(Social_group)){
        
        #Check if memory slot is open
         if(Social_group[s,v] == 0){
        
           #If true, save the information to the empty memory space
           Social_group[s,v] <- Info$xi[2]
           Social_group[s,(v+1)] <- Info$yi[2]
           
           #Break out of loop and continue to next agent
           break
         }
        }
  
        #If full, sample memory space, and replace with new value (integrate)
        
        #which place in memory should the new info go
        
        #Sample which memory should be replaced. There are nMemo possible values
        sample_num <- as.character(sample(1:((ncol(Social_group)-9)/2), size=1))
        
        #Now i have the location (sample_num), I just need to plot in the new                   information
        colnames_df <- colnames(Social_group[s,])
       
        memory_to_replace <- as.data.frame(str_detect(colnames_df, sample_num))
        
        #Now I know the columns in which the new info should go. So I need to put it there
        column_social <- numeric()
        for(m in 1:nrow(memory_to_replace)){ #Two rows to loop through: memory x and y
          if(memory_to_replace[m,] == TRUE){
            
            column_social <- c(column_social, m) # Saving the index of the columns
            column_social <- as.list(column_social)
            
          }
        }
        x_coord <- column_social[[1]] # memory x coordinate column number
        y_coord <- column_social[[2]] # memory y coordinate column number
        
        #Reset agent position to 0 before updating memory
        Social_group$x[s] <- 0
        Social_group$y[s] <- 0
        
        # And now we save the new memory in the right location
        Social_group[s,][,x_coord] <- Info$xi[2]
        Social_group[s,][,y_coord] <- Info$yi[2]
        
        #Now memory is updated. Time to update location on attitude space
        
        #Because the location of the agent is dependent on its memory, it will always be zero to begin with because almost all memories are "neutral". I need to average only over the non-zero memories.
        
        #Number of non-zero columns per agent
        nonZero <- sum(apply(Social_group[s,], 2, function(c)sum(c!=0)))
        
        # Averaging the x-values over the number of memories (of value x)
        Social_group$x[s] <- sum(Social_group[s,seq(10, ncol(Social_group), 2)])/((nonZero-7)/2) # -7 because there are always those 7 non memory columns which are nonZero (at this place in the loop x and y are always zero)
        
        # Averaging the y-values over the number of memories (of value y)
        Social_group$y[s] <- sum(Social_group[s,seq(11, ncol(Social_group), 2)])/((nonZero-7)/2) 
        
        return(Social_group)
        } #Done integrating


#Define Agents
GenPop <- function(nPop, nMemo, Lat_accept, Sharpness, nGroups){
  

Agent <- data.frame(AgentNo = 1:nPop, # agent number
                    x = 0, # y coordinate
                    y = 0, # x coordinate
                    Lat = Lat_accept, #latitude of acceptance
                    Sharpness = Sharpness,
                    Valence = 1,
                    No_of_Shares = 1,
                    stringsAsFactors = FALSE)

#This column can't be zero because I use it for calculations later
Agent$No_of_Shares <- as.numeric(Agent$No_of_Shares)

#Assigning each agent to a group
groups <- as.data.frame(matrix(0, nrow = nrow(Agent), ncol = 1))
groups <- rename(groups, Group = V1)

for(a in 1:nrow(groups)){
  
  #It's debatable whether there should be an equal amount of members in each group, or if it should be random. I'm going to start with random amounts (but roughly equal), but later I might change in to be able to control group dynamics.
  groups[a,] <- sample(LETTERS[1:nGroups], 1, replace = TRUE)
}

#Deciding a "sharing threshold" for each agent
sharing <- as.data.frame(matrix(0, nrow = nrow(Agent), ncol = 1))
sharing <- rename(sharing, Share = V1)

for(a in 1:nrow(groups)){
  
  #Each agent will have a value indicating how likely they are to share their point of     view to other agents of their group.
  sharing[a,] <- runif(1,0,2)
}

#Building memory as dataframe with nMemo*2 column (x & y coordinates)
memory <- as.data.frame(matrix(0, nrow = nrow(Agent), ncol = nMemo*2))

prefixX <- "memory x"
prefixY <- "memory y"
suffix <- seq(1:nMemo)

namesx <- paste(prefixX, suffix, sep = "")
namesy <- paste(prefixY, suffix, sep = "")


colnames(memory)[seq(1,ncol(memory),2)] <- c(namesx)
colnames(memory)[seq(2,ncol(memory),2)] <- c(namesy)

Agent <- cbind(Agent, sharing, groups, memory)

return(Agent) 
  }


#range01 <- function(x){(x-min(x))/(max(x)-min(x))}
range01 <- function(x){(x-0.0001)/(2.828427-0.0001)}

#Creating info dataframe
Info <- data.frame(Info_num = 1:2, # Two pieces of into: main and social
                   xi = 0, # x coordinate for info
                   yi = 0) # y coordinate for info


#Defining ABM function
ABM1 <- function(Agents, Iterations, Plot_freq, Bias, Social_posting){

  #Loop through time
  for(t in 1:Iterations){
    
    #You could argue that the (mainstream) information should have a biased distribution      since the attitudinal space represents a certain topic, and mainstream media is         unlikely to represent it in a completely random manner.
    if(Bias == "None"){
    
    #Creating neutral information
    Info$xi[1] <- runif(1, -1, 1) #No bias
    Info$yi[1] <- runif(1, -1, 1) #No bias
    
    }
  
   #Conditional statement for Bias
    if(Bias == "Positive"){
    
    
    #Creating biased information
    Info$xi[1] <- rnorm(1, 0.5, 1) #positive bias
    Info$yi[1] <- rnorm(1, 0.5, 1) #Positive bias
    
    #keeping the values between -1 and 1
    while(Info$xi[1] < -1 | Info$xi[1] > 1 | Info$yi[1] < -1 | Info$yi[1] > 1){ 
    Info$xi[1] <- rnorm(1, 0.5, 1) #positive bias
    Info$yi[1] <- rnorm(1, 0.5, 1) #Positive bias
    
    }
  }
    
    if(Bias == "Negative"){
    
    #Creating biased information
    Info$xi[1] <- rnorm(1, -0.5, 1) #negative bias
    Info$yi[1] <- rnorm(1, -0.5, 1) #negative bias
    
    #keeping the values between -1 and 1
    while(Info$xi[1] < -1 | Info$xi[1] > 1 | Info$yi[1] < -1 | Info$yi[1] > 1){ 
    Info$xi[1] <- rnorm(1, -0.5, 1) #negative bias
    Info$yi[1] <- rnorm(1, -0.5, 1) #negative bias
    
    }
    }
    
    #Loop through population
    for(i in sample(c(1:nrow(Agents)))){ #loop in random order
      
      #Find the acceptance latitude of agent
      Latitude_m <- Agents$Lat[i]
      
      #Find attitude sharpness of agent
      Sharpness_m <- Agents$Sharpness[i]
      
      # Present information to agent:
      
      #which information will the agent meet
      Info_meet <- Info[1,]
      
      #What is the distance between agent and info
      Distance_main <- sqrt( ((Agents$x[i] - Info$xi[1])^2) + ((Agents$y[i] -
                                                                  Info$yi[1])^2) )
      
      #What is the trustworthiness of info
      Trust <- Info$Trust[1]
      
      #What is the chance they they will integrate
      RandNum <- runif(1,0,1)
      if (RandNum < ((Latitude_m^Sharpness_m)/
                     (Distance_main^Sharpness_m+Latitude_m^Sharpness_m))){
        
        Agents <- Integrate_main(Agents = Agents,
                                 i = i,
                                 Info = Info) 
        
      } else{ #Contrast effect:
        
        if(Distance_main > Lat_reject){
          
        #Check if information is positive or negative, then pull in opposite direction:
            if (Info$xi[1] >= 0){
            
            #pull valence in opposite direction
            Info$xi[1] <- (Info$xi[1]) - ((range01(Distance_main))*2) 
            
          } else{ #If Info$xi[1] <= 0 (negative)
            
            #Pull valence in opposite direction
            Info$xi[1] <- (Info$xi[1]) - (-(range01(Distance_main))*2)
          }
          
          #Same thing for Y:
          if (Info$yi[1] >= 0){
            
            #pull valence in opposite direction
            
            Info$yi[1] <- (Info$yi[1]) - ((range01(Distance_main))*2) 
            
          } else{ #If Info$yi[1] <= 0 (negative)
            
            #Pull valence in opposite direction
            Info$yi[1] <- (Info$yi[1]) - (-(range01(Distance_main))*2)
          } #Done implementing boomerang effect
        
          #Integrate new and reversed information:
          Agents <- Integrate_main(Agents = Agents, 
                                   i = i, 
                                   Info = Info)
        }
      } #Done integrating mainstream information 
      
     #Determine the absolute valency of agent "opinion" 
      Agents$Valence[i] <- sqrt((Agents$x[i])^2 + (Agents$y[i])^2)
      
      #Turn Social_posting on/off
      if(Social_posting == TRUE){
      
      #For every agent, see if they reach over the sharing threshold. Agents with high sharing value will have an easier time breaching the threshold  and will share more often.
        #Check if agent valency exceeds sharing threshold:
      if(Agents$Valence[i] > Agents$Share[i]){
        
        #Index forward No_of_Shares
        Agents$No_of_Shares[i] <-  Agents$No_of_Shares[i] + 1
        
        #If true, the agent will "post" it's location to members of it's group
        Info$xi[2] <- Agents$x[i]
        Info$yi[2] <- Agents$y[i]
        
        #Grab subset of agents who are in the same group as agent "i"
        #Find a way to have each person in social group integrate agent i's information.
        Social_group <- subset(Agents, Agents$Group == Agents$Group[i])
        
        #Removing agent "i" from subset, so she doesn't integrate her own information
        Social_group <- Social_group %>% 
          filter(AgentNo != i)
        
        #Loop through each agent in social group as they try to integrate the information
        for(s in sample(c(1:nrow(Social_group)))){ #Loop in random order
          
          #Find the acceptance latitude of agent
          Latitude_social <- Social_group$Lat[s]
      
          #Find attitude sharpness of agent
          Sharpness_social <- Social_group$Sharpness[s]
          
          #distance between agent and social post
          Distance_social <- sqrt( ((Social_group$x[s] - Info$xi[2])^2) + 
                                     ((Social_group$y[s] -   Info$yi[2])^2) )
          
           #Each agent tries to integrate
          #What is the chance they they will integrate
        RandNum_social <- runif(1,0,1)
        if (RandNum_social <
            Latitude_social^Sharpness_social/(Distance_social^Sharpness_social+Latitude_social^Sharpness_social)){
        
        #if true, integrate
        Social_group <- Integrate_social(Agents = Agents, 
                                         Social_group = Social_group, 
                                         s = s,
                                         Info = Info)
       
      #Merge function doesn't work. But here I replace updated information (from Group) to original dataframe
      Agent_names <- Social_group$AgentNo
    for(x in Agent_names){
      
      #Check where the agent is in the original dataframe (AgentNo in Agents)
      if(Social_group$AgentNo[x] %in% Agents$AgentNo){
        
        #If true, replace old data new updated data
        Agents[Agents$AgentNo == x,] <- Social_group[Social_group$AgentNo == x,]
      
          }
        } #Done updating (merging) dataframe
      } else { #Adding boomerang effect
        
        if(Distance_social > Lat_reject){
          
          if (Info$xi[2] >= 0){
            Distance_social <- 0.5
            #pull valence in opposite direction
            Info$xi[2] <- (Info$xi[2]) - ((range01(Distance_social))*2)
            
          } else{ #If Info$xi[2] <= 0 (negative)
            
            #Pull valence in opposite direction
            Info$xi[2] <- (Info$xi[2]) - (-(range01(Distance_social))*2)
          }
          
        # "Flip" y
          if (Info$yi[2] >= 0){
            
            #pull valence in opposite direction
            Info$yi[2] <- (Info$yi[2]) - ((range01(Distance_social))*2) 
            
          } else{ #If Info$xi[1] <= 0 (negative)
            
            Info$yi[2] <- (Info$yi[2]) - (-(range01(Distance_social))*2)
          } #Done implementing boomerang effect
          
          Social_group <- Integrate_social(Agents = Agents, 
                                           Social_group = Social_group, 
                                           s = s,
                                           Info = Info)
          
          #Replace updated information (from Group) to original dataframe
          Agent_names <- Social_group$AgentNo
          for(x in Agent_names){
            
            #Check where the agent is in the original dataframe (AgentNo in Agents)
            if(Social_group$AgentNo[x] %in% Agents$AgentNo){
              #If true, replace old data new updated data
              Agents[Agents$AgentNo == x,] <- Social_group[Social_group$AgentNo == x,]
              
          }
        } # Done merging
      
      } # Reject integrate social
    } # Done integrating rejection social
  } # Done looping through social group
  } #Agents valence > Agents Share
  
  
      } # Social posting == TRUE 
    } # Done looping through agents
    #Visualization:
    if(t %% Plot_freq == 0 | t == 1){

    plot <- Agents %>%
    ggplot(aes(x, y, color = Group)) + geom_point(aes(size = Share)) + xlim(-1, 1) + ylim(-1, 1) + theme(legend.position = "None") + ggtitle(paste("TickNo", t)) +
      scale_size(trans = 'reverse')
    
    print(plot)
    }
  } # Done looping through time
  Agents$No_of_Shares <- Agents$No_of_Shares - 1 # Subtracting one so it's the correct No_of_Shares
  
  return(Agents)
}
```

#Playing around with probability function
```{r}
D <- 0.5 #Latitude of acceptance: The distance at which probability of information is 50%

DR <- 1 #Latitude of rejection: The distance at which information exceeding this amount will be reversed and then integrated

d <- 0.4 #Distance between agent and information
sharp <- 5 #The speed at which probability of integration will drop to zero around the latitude of acceptance

#Max distance?
# x1 <- -1
# y1 <- -1
# 
# x2 <- 1
# y2 <- 1
#Distance function
# sqrt( ((x2-x1)^2)+((y2-y1)^2)) # = 2.828427

D^sharp/(d^sharp+D^sharp)

```

###RUNNING MODEL TIME
```{r}
set.seed(234)
#The first model will get some parameters which are copied to all models to reduce the stochastic nature of sampling. The parameters are: start location (x & y), sharing threshold and Group. They will be copied manually because they are coded into the GenPop function.

#MODEL 1:
Lat_reject <- 0.5

Agents_mod1 <- GenPop(nPop = 500, nMemo = 20, Lat_accept = 0.3, Sharpness = 5, nGroups = 10)

#Where do the agents start the simulation (default (0,0))
Agents_mod1[,2] <- runif(nrow(Agents_mod1), -1, 1) #Random x coordinates
Agents_mod1[,3] <- runif(nrow(Agents_mod1), -1, 1) #Random y coordinates

#After generating random starting positions for the Agents, also make the first memory equal to that starting position, so the first memory they integrate doesn't have too much influence, and they "remember" where they started.
Agents_mod1[,10] <- Agents_mod1[,2] #memory 1x
Agents_mod1[,11] <- Agents_mod1[,3] #memory 1y

model1 <- ABM1(Agents = Agents_mod1, Iterations = 400, Plot_freq = 50, Bias = "None", Social_posting = FALSE)

#MODEL 2:
Lat_reject <- 1

Agents_mod2 <- GenPop(nPop = 500, nMemo = 20, Lat_accept = 0.5, Sharpness = 5, nGroups = 10)

#Where do the agents start the simulation (default (0,0))
Agents_mod2[,2] <- Agents_mod1[,2] #Random x coordinates (from model 1)
Agents_mod2[,3] <- Agents_mod1[,3] #Random y coordinates (from model 1)

Agents_mod2[,10] <- Agents_mod2[,2] #memory 1x
Agents_mod2[,11] <- Agents_mod2[,3] #memory 1y

Agents_mod2[,8] <- Agents_mod1[,8] #Share column (from model 1)

Agents_mod2[,9] <- Agents_mod1[,9] #Group column (from model 1)

model2 <- ABM1(Agents = Agents_mod2, Iterations = 400, Plot_freq = 50, Bias = "None", Social_posting = FALSE)

#MODEL 3:
Lat_reject <- 1.5

Agents_mod3 <- GenPop(nPop = 500, nMemo = 20, Lat_accept = 0.7, Sharpness = 5, nGroups = 10)

#Where do the agents start the simulation (default (0,0))
Agents_mod3[,2] <- Agents_mod1[,2] #Random x coordinates (from model 1)
Agents_mod3[,3] <- Agents_mod1[,3] #Random y coordinates (from model 1)

Agents_mod3[,10] <- Agents_mod3[,2] #memory 1x
Agents_mod3[,11] <- Agents_mod3[,3] #memory 1y

Agents_mod3[,8] <- Agents_mod1[,8] #Share column (from model 1)

Agents_mod3[,9] <- Agents_mod1[,9] #Group column (from model 1)

model3 <- ABM1(Agents = Agents_mod3, Iterations = 400, Plot_freq = 50, Bias = "None", Social_posting = FALSE)

#MODEL 4:
Lat_reject <- 2

Agents_mod4 <- GenPop(nPop = 500, nMemo = 20, Lat_accept = 1, Sharpness = 5, nGroups = 10)

#Where do the agents start the simulation (default (0,0))
Agents_mod4[,2] <- Agents_mod1[,2] #Random x coordinates (from model 1)
Agents_mod4[,3] <- Agents_mod1[,3] #Random y coordinates (from model 1)

Agents_mod4[,10] <- Agents_mod4[,2] #memory 1x
Agents_mod4[,11] <- Agents_mod4[,3] #memory 1y

Agents_mod4[,8] <- Agents_mod1[,8] #Share column (from model 1)

Agents_mod4[,9] <- Agents_mod1[,9] #Group column (from model 1)

model4 <- ABM1(Agents = Agents_mod4, Iterations = 400, Plot_freq = 50, Bias = "None", Social_posting = FALSE)

#MODEL 5:
Lat_reject <- 0.5

Agents_mod5 <- GenPop(nPop = 500, nMemo = 20, Lat_accept = 0.3, Sharpness = 5, nGroups = 10)

#Where do the agents start the simulation (default (0,0))
Agents_mod5[,2] <- Agents_mod1[,2] #Random x coordinates (from model 1)
Agents_mod5[,3] <- Agents_mod1[,3] #Random y coordinates (from model 1)

Agents_mod5[,10] <- Agents_mod5[,2] #memory 1x
Agents_mod5[,11] <- Agents_mod5[,3] #memory 1y

Agents_mod5[,8] <- Agents_mod1[,8] #Share column (from model 1)

Agents_mod5[,9] <- Agents_mod1[,9] #Group column (from model 1)

model5 <- ABM1(Agents = Agents_mod5, Iterations = 400, Plot_freq = 50, Bias = "None", Social_posting = TRUE)

#MODEL 6:
Lat_reject <- 1

Agents_mod6 <- GenPop(nPop = 500, nMemo = 20, Lat_accept = 0.5, Sharpness = 5, nGroups = 10)

#Where do the agents start the simulation (default (0,0))
Agents_mod6[,2] <- Agents_mod1[,2] #Random x coordinates (from model 1)
Agents_mod6[,3] <- Agents_mod1[,3] #Random y coordinates (from model 1)

Agents_mod6[,10] <- Agents_mod6[,2] #memory 1x
Agents_mod6[,11] <- Agents_mod6[,3] #memory 1y

Agents_mod6[,8] <- Agents_mod1[,8] #Share column (from model 1)

Agents_mod6[,9] <- Agents_mod1[,9] #Group column (from model 1)

model6 <- ABM1(Agents = Agents_mod6, Iterations = 400, Plot_freq = 50, Bias = "None", Social_posting = TRUE)

#MODEL 7:
Lat_reject <- 1.5

Agents_mod7 <- GenPop(nPop = 500, nMemo = 20, Lat_accept = 0.7, Sharpness = 5, nGroups = 10)

#Where do the agents start the simulation (default (0,0))
Agents_mod7[,2] <- Agents_mod1[,2] #Random x coordinates (from model 1)
Agents_mod7[,3] <- Agents_mod1[,3] #Random y coordinates (from model 1)

Agents_mod7[,10] <- Agents_mod7[,2] #memory 1x
Agents_mod7[,11] <- Agents_mod7[,3] #memory 1y

Agents_mod7[,8] <- Agents_mod1[,8] #Share column (from model 1)

Agents_mod7[,9] <- Agents_mod1[,9] #Group column (from model 1)

model7 <- ABM1(Agents = Agents_mod7, Iterations = 400, Plot_freq = 50, Bias = "None", Social_posting = TRUE)

#MODEL 8:
Lat_reject <- 2

Agents_mod8 <- GenPop(nPop = 500, nMemo = 20, Lat_accept = 1, Sharpness = 5, nGroups = 10)

#Where do the agents start the simulation (default (0,0))
Agents_mod8[,2] <- Agents_mod1[,2] #Random x coordinates (from model 1)
Agents_mod8[,3] <- Agents_mod1[,3] #Random y coordinates (from model 1)

Agents_mod8[,10] <- Agents_mod8[,2] #memory 1x
Agents_mod8[,11] <- Agents_mod8[,3] #memory 1y

Agents_mod8[,8] <- Agents_mod1[,8] #Share column (from model 1)

Agents_mod8[,9] <- Agents_mod1[,9] #Group column (from model 1)

model8 <- ABM1(Agents = Agents_mod8, Iterations = 400, Plot_freq = 50, Bias = "None", Social_posting = TRUE)

```


#Random analyses
```{r}
Lat_reject <- 1.5
Lat_reject_social <- 1.5# Maybe it should be the double of lat of accept. Bigger latitude of acceptance means the agents will integrate more information they disagree with, and reinforce their current position. 
Agents20 <- GenPop(nPop = 300, nMemo = 20, Lat_accept = 0.3, Sharpness = 5, nGroups = 7)

#Where do the agents start the simulation (default (0,0))
Agents20[,2] <- runif(nrow(Agents20), -1, 1) #Random x coordinates
Agents20[,3] <- runif(nrow(Agents20), -1, 1) #Random y coordinates

#After generating random starting positions for the Agents, also make the first memory equal to that starting position, so the first memory they integrate doesn't have too much influence, and they "remember" where they started.
Agents20[,10] <- Agents20[,2] #memory 1x
Agents20[,11] <- Agents20[,3] #memory 1y


Out11 %>%
    ggplot(aes(x, y, color = Group)) + geom_point(aes(size = Share)) + xlim(-1, 1) + ylim(-1, 1) +  ggtitle(paste("TickNo", 100)) +
      scale_size(trans = 'reverse')

Out3 %>% 
  ggplot(aes(No_of_Shares, color = Group)) + geom_density()


Out11 %>% 
  ggplot(aes(Share, color = Group)) + geom_density()

Agents_mod1 %>%
  count(Group, sort = T) %>%  #Group size + density might affect radicalization.
  mutate(group_density = n/sum(n))
  

Out12 %>% 
  group_by(Group) %>% 
  summarise(mean_no_share = mean(No_of_Shares),
            sd_no_share = sd(No_of_Shares),
            mean_valence = mean(Valence),
            sd_valence = sd(Valence))

Out12 %>% 
  group_by(Group) %>% 
  summarise(group_size = count(AgentNo))
  

mean(Out12$Valence)
mean(Out13$Valence)

Out12 %>% 
  group_by(Group) %>% 
  summarise(mean_x = mean(x)) %>% 
  ggplot(aes(x = Group, y = mean_x, fill = Group)) +
  geom_bar(stat = "identity") + 
    theme_classic() +
    labs(
        x = "Group",
        y = "Mean X",
        title = paste(
            "Mean X by group"
        )
    )

Out12 %>% 
  group_by(Group) %>% 
  summarise(mean_y = mean(y)) %>% 
  ggplot(aes(x = Group, y = mean_y, fill = Group)) +
  geom_bar(stat = "identity") + 
    theme_classic() +
    labs(
        x = "Group",
        y = "Mean Y",
        title = paste(
            "Mean Y by group"
        )
    )

Out13 %>% 
  group_by(Group) %>% 
  summarise(mean_valence = mean(Valence)) %>% 
  ggplot(aes(x = Group, y = mean_valence, fill = Group)) +
  geom_bar(stat = "identity") + 
    theme_classic() +
    labs(
        x = "Group",
        y = "Mean Valence",
        title = paste(
            "Mean valence by group"
        )
    )

Out3 %>% 
  ggplot(aes(Valence, color = Group)) + geom_boxplot()

Out9 %>% 
  ggplot(aes(x, color = Group)) + geom_boxplot()

Out13 %>% 
  ggplot(aes(x)) + geom_density() + ggtitle("Clustering of agents across X")

Out13 %>% 
  ggplot(aes(y)) + geom_density() + ggtitle("Clustering of agents across Y")
  

mean(Out1$x)
sd(Out1$x)
sd(Out1$y)


#For tomorrow: 

```
 

  
#Bayesian analysis
```{r}

##Doing analysis on several datasets
Out$Social_posting <- 0
Out4$Social_posting <- 1

SP_contrast <- rbind(Out, Out4)
str(SP_contrast)
SP_contrast$Social_posting <- as.factor(SP_contrast$Social_posting)
SP_contrast$AgentNo <- as.factor(SP_contrast$AgentNo)

#Let's try to model valence as outcome
SP_contrast %>% 
  ggplot(aes(Valence)) + geom_density(aes(color = Social_posting)) #Semi normal distr.

SP_contrast %>% 
  group_by(Social_posting) %>% 
  summarise(mean_valence = mean(Valence),
            sd_valence = sd(Valence))

f1 <- bf(Valence ~ Social_posting + (1 | AgentNo))

get_prior(f1, data = SP_contrast, family = gaussian())

f1_prior <- c(
  prior(normal(0, 0.1), class = b), # No diff
  prior(student_t(3, 0, 2.5), class = sd), #Default
  prior(student_t(3, 0, 2.5), class = sigma) #Default
)

m1_prior <- brm(
  f1,
  data = SP_contrast,
  family = gaussian(),
  prior = f1_prior,
  sample_prior = "only",
  chains = 2,
  cores = 4,
  backend="cmdstanr",
  threads = threading(2),
  )

pp_check(m1_prior, nsamples = 50)


m1_post <- brm(
  f1,
  data = SP_contrast,
  family = gaussian(),
  prior = f1_prior,
  sample_prior = T,
  chains = 2,
  cores = 4,
  backend="cmdstanr",
  threads = threading(2),
  )

pp_check(m1_post, nsamples = 50)

conditional_effects(m1_post)

posterior_gauss <- posterior_samples(m1_post)
summary(m1_post)
colnames(posterior_gauss)

ggplot(posterior_gauss) + #Plotting the beta prior + posterior
  theme_classic() +
  geom_density(aes(prior_b), fill="red", alpha=0.3) +
  geom_density(aes(b_Social_posting1), fill="blue", alpha=0.5)

ggplot(posterior_gauss) + #Plotting the sigma prior + posterior
  theme_classic() +
  geom_density(aes(prior_sigma), fill="red", alpha=0.3) +
  geom_density(aes(sigma), fill="blue", alpha=0.5)

##SAMPLING QUALITY
mcmc_trace(m1_post, 
           pars = c("b_Social_posting1", 
                    "sd_AgentNo__Intercept",
                    'sigma')) +
  theme_classic() 

mcmc_rank_overlay(m1_post,
                  pars = c("b_Social_posting1", 
                    "sd_AgentNo__Intercept",
                    'sigma')) + 
  theme_classic()


```

#Frequentist analysis
```{r}
##Frequentist stats

model <- lmerTest::lmer(Valence ~ Social_posting + (1|AgentNo), data = SP_contrast)

model1 <- lmerTest::lmer(Valence ~ Social_posting + Share + (1|AgentNo), data = SP_contrast)
summary(model); summary(model1)
?isSingular
?t.test
t.test(Valence, )

df <- (matrix(0, nrow = 200, ncol = 0))

df$Social <- SP_contrast %>%
  filter(Social_posting == 1) %>% 
  select(Valence)

df$nonSocial <- SP_contrast %>%
  filter(Social_posting == 0) %>% 
  select(Valence)

df$ID <- 1:200
df <- as.data.frame(df)
df <- rename(df, Social = Valence)
df <- rename(df, nonSocial = Valence.1)
#Now it's in the format to do a simple t.test
t.test(Valence ~ Social_posting, paired = T, data = SP_contrast, var.equal = T)


```

#Old models
```{r}
###OLD MODELS###
Out <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "None", Social_posting = TRUE) # nmemo 20, ngroups 7, bias none, npop 100, lat reject 0.7, lat accept 0.3

Out1 <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "None", Social_posting = TRUE) # nmemo 20, ngroups 4, bias none, npop 100, lat reject 0.7, lat accept 0.3, iterations 100, sharpness 20

Out2 <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "Positive", Social_posting = TRUE) # nmemo 20, ngroups 4, bias Positive, npop 100, lat reject 0.7, lat accept 0.3, iterations 100, sharpness 20

Out3 <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "Positive", Social_posting = TRUE) # nmemo 20, ngroups 5, bias Positive, npop 100, lat reject 1, lat accept 0.3, iterations 100, sharpness 5

Out4 <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "Positive", Social_posting = TRUE) # nmemo 10, ngroups 10, bias Positive, npop 200, lat reject 1, lat accept 0.5, iterations 100

Out5 <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "Positive", Social_posting = TRUE) #nPop = 200, nMemo = 20, Lat_accept = 0.3, Sharpness = 5, nGroups = 7, lat reject 0.7

Out6 <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "Positive", Social_posting = TRUE) #nPop = 200, nMemo = 20, Lat_accept = 0.6, Sharpness = 5, nGroups = 7, lat reject 0.7

Out7 <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "Positive", Social_posting = TRUE) #nPop = 200, nMemo = 20, Lat_accept = 0.2, Sharpness = 5, nGroups = 7, lat reject 0.7

Out8 <- ABM1(Agents = Agents20, Iterations = 100, Plot_freq = 10, Bias = "Positive", Social_posting = FALSE) #nPop = 200, nMemo = 20, Lat_accept = 0.2, Sharpness = 5, nGroups = 7, lat reject 0.7

Out9 <- ABM1(Agents = Agents20, Iterations = 400, Plot_freq = 10, Bias = "Positive", Social_posting = TRUE) #nPop = 100, nMemo = 20, Lat_accept = 0.3, Sharpness = 5, nGroups = 5, bias positive

Out10 <- ABM1(Agents = Agents20, Iterations = 200, Plot_freq = 10, Bias = "None", Social_posting = TRUE) #nPop = 100, nMemo = 20, Lat_accept = 0.3, Sharpness = 5, nGroups = 5, bias None

Out11 <- ABM1(Agents = Agents20, Iterations = 300, Plot_freq = 10, Bias = "None", Social_posting = TRUE) #nPop = 100, nMemo = 15, Lat_accept = 0.3, Sharpness = 5, nGroups = 5, bias None

Out12 <- ABM1(Agents = Agents20, Iterations = 300, Plot_freq = 10, Bias = "None", Social_posting = TRUE) #nPop = 300, nMemo = 20, Lat_accept = 0.3, Sharpness = 5, nGroups = 7, bias None

Out13 <- ABM1(Agents = Agents20, Iterations = 300, Plot_freq = 10, Bias = "None", Social_posting = FALSE)
```

