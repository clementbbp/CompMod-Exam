---
title: "Information Integration Project"
author: "Clement Peters"
date: "5/1/2021"
output: html_document
---

#What do I need to do:

1. Define Agents
  1.1 What types. Agents + info-bits
  1.2 What parameters do they have
    1.2.1 *Agents*
        Memory
            How large is memory? Parameter*
        Location in attitude space (xy coordinate)
            This is the mean of the attitudes they hold in memory
            I can make a parameter specifying how closely to the middle the population               will start
    1.2.2 *Info bit*
        Lifespan
            Should be one tick. If they are not integrated they disappear
        Location in attitude space
            Should be random, with a distribution of -1 to 1 on both axis. This will
            represent central information output. Could also be programmed with a                   certain bias, which might represent central information better.
        Trustworthiness score
            How trustworthy is the information perceived generally?
  1.3 What will they do each tick?
    1.3.1 Agents will try to integrate the infobit which is created. Success will depend
        on the information integration formula which gives a probability of being inte-
        grated. *If the info-bit is integrated, they will move closer to that info-bit in         attitude space by averaging and updating their memory*
    1.3.2 If social media is turned on, then the agents will have a probability to share
          their location in attitude space for others to integrate
    1.3.3 Info bits will disappear after one tick
    1.3.4
        
      
 
```{r}
##Packages
pacman::p_load(tidyverse, stringr, dplyr)
```
 
        
  
#d=√((x2−x1)^2+(y2−y1)^2) the distance between two points
# f(d;D,δ) = D^δ/(d^δ+D^δ) Integration formula
  
```{r}
D <- 0.5 #What should the max latitude be when the maximum distance in the attitude space can only be 2.83. It is realistic that a piece of information has 0.5 chance of being integrated, when it's theoretically as far away from the agent as possible? 
d <- 0.5
sharp <- 20
#Max distance?
# x1 <- -1
# y1 <- -1
# 
# x2 <- 1
# y2 <- 1
# sqrt( ((x2-x1)^2)+((y2-y1)^2)) # = 2.828427

D^sharp/(d^sharp+D^sharp)


#Define Agents
GenPop <- function(nPop, nMemo, Lat_accept, Sharpness, nGroups){
  

Agent <- data.frame(AgentNo = 1:nPop, # agent number
                    x = 0, # y coordinate
                    y = 0, # x coordinate
                    Lat = Lat_accept, #latitude of acceptance
                    Sharpness = Sharpness,
                    Valence = 1,
                    Empty = "Empty",
                    stringsAsFactors = FALSE)

#Assigning each agent to a group
groups <- as.data.frame(matrix(0, nrow = nrow(Agent), ncol = 1))
groups <- rename(groups, Group = V1)

for(a in 1:nrow(groups)){
  
  #It's debatable whether there should be an equal amount of members in each group, or if it should be random. I'm going to start with random amounts (but roughly equal), but later I might change in to be able to control group dynamics.
  groups[a,] <- sample(LETTERS[1:nGroups], 1, replace = TRUE)
}

#Deciding a "sharing threshold" for each agent
sharing <- as.data.frame(matrix(0, nrow = nrow(Agent), ncol = 1))
sharing <- rename(sharing, Share = V1)

for(a in 1:nrow(groups)){
  
  #Each agent will have a value indicating how likely they are to share their point of     view to other agents of their group. I assume most people will not be very likely to share, while a few will likely always share.
  sharing[a,] <- rexp(1, 2)
  
  
}

#Building memory as dataframe with nMemo*2 column (x & y coordinates)
memory <- as.data.frame(matrix(0, nrow = nrow(Agent), ncol = nMemo*2))

prefixX <- "memory x"
prefixY <- "memory y"
suffix <- seq(1:nMemo)

namesx <- paste(prefixX, suffix, sep = "")
namesy <- paste(prefixY, suffix, sep = "")


colnames(memory)[seq(1,ncol(memory),2)] <- c(namesx)
colnames(memory)[seq(2,ncol(memory),2)] <- c(namesy)

Agent <- cbind(Agent, sharing, groups, memory)

return(Agent) 
  }

          


Agents <- GenPop(nPop = 100, nMemo = 10, Lat_accept = 0.3, Sharpness = 2, nGroups = 5)
  Agents %>% 
  count(Group, sort = T)

Info <- data.frame(Info_num = 1:2, # Two pieces of into: main and social
                   xi = 0.5, # x coordinate for info
                   yi = 0.3, # y coordinate for info
                   Trust = 0, # Trustworthiness score Parameter*
                   TimeExist = 0)

#Where do the agents start the simulation (default (0,0))
Agents[,2] <- runif(nrow(Agents), -1, 1) #Random x coordinates
Agents[,3] <- runif(nrow(Agents), -1, 1) #Random y coordinates



ABM1 <- function(Agents, Iterations, Plot_freq, Bias, Social_posting){

  #Loop through time
  for(t in 1:Iterations){
    
    #You could argue that the (mainstream) information should have a biased distribution      since the attitudinal space represents a certain topic, and mainstream media is         unlikely to represent it in a completely random manner.
    if(Bias == "None"){
    
    #Creating neutral information
    Info$xi[1] <- runif(1, -1, 1) #No bias
    Info$yi[1] <- runif(1, -1, 1) #No bias
    
    }
  
   #Conditional statement for Bias
    if(Bias == "Positive"){
    
    
    #Creating biased information
    Info$xi[1] <- rnorm(1, 0.5, 1) #positive bias
    Info$yi[1] <- rnorm(1, 0.5, 1) #Positive bias
    
    #keeping the values between -1 and 1
    while(Info$xi[1] < -1 | Info$xi[1] > 1 | Info$yi[1] < -1 | Info$yi[1] > 1){ 
    Info$xi[1] <- rnorm(1, 0.5, 1) #positive bias
    Info$yi[1] <- rnorm(1, 0.5, 1) #Positive bias
    
    }
  }
    
    if(Bias == "Negative"){
    
    #Creating biased information
    Info$xi[1] <- rnorm(1, -0.5, 1) #negative bias
    Info$yi[1] <- rnorm(1, -0.5, 1) #negative bias
    
    #keeping the values between -1 and 1
    while(Info$xi[1] < -1 | Info$xi[1] > 1 | Info$yi[1] < -1 | Info$yi[1] > 1){ 
    Info$xi[1] <- rnorm(1, -0.5, 1) #negative bias
    Info$yi[1] <- rnorm(1, -0.5, 1) #negative bias
    
    }
  }
  
    
    #Loop through population
    for(i in 1:nrow(Agents)){
      
      #Find the acceptance latitude of agent
      Latitude_m <- Agents$Lat[i]
      
      #Find attitude sharpness of agent
      Sharpness_m <- Agents$Sharpness[i]
      
      # Present information to agent:
      
      #which information will the agent meet
      Info_meet <- Info[1,]
      
      #What is the distance between agent and info
      Distance_main <- sqrt( ((Agents$x[i] - Info$xi[1])^2) + ((Agents$y[i] -
                                                                  Info$yi[1])^2) )
      
      #What is the trustworthiness of info
      Trust <- Info$Trust[1]
      
      #What is the chance they they will integrate
      RandNum <- runif(1,0,1)
      
      if (RandNum < ((Latitude_m^Sharpness_m)/
                     (Distance_main^Sharpness_m+Latitude_m^Sharpness_m))){
        
        # #If true, check if memory is full
         for(j in 10:ncol(Agents)){

        #Check if memory slot is open
         if(Agents[i,j] == 0){
           j <- as.numeric(j)

           #If true, save the information to the empty memory space
           Agents[i,j] <- Info$xi[1]
           Agents[i,(j+1)] <- Info$yi[1]

            #Break out of loop and continue to next agent
            break
         }
           
        }
  
        #If full, sample memory space, and replace with new value (integrate)
        
        #which place in memory should the new info go
        
        #Sample which memory should be replaced. There are nMemo possible values
        sample_num <- as.character(sample(1:((ncol(Agents)-9)/2), size=1)) 
        
        #Now i have the location (sample_num), I just need to plot in the new                   information
        colnames_df <- colnames(Agents[i,])
       
        memory_to_replace <- as.data.frame(str_detect(colnames_df, sample_num))
        
        #Now I know the columns in which the new info should go. So I need to put it there
        column <- numeric()
        for(k in 1:nrow(memory_to_replace)){
          if(memory_to_replace[k,] == TRUE){
            k <- as.numeric(k)
            column <- c(column, k) # Saving the index of the columns
            #column <- as.list(column)
            
          }
        }
        x_coord <- column[[1]] # memory x coordinate column number
        y_coord <- column[[2]] # memory y coordinate column number
        
        # And now we save the new memory in the right location
        Agents[i,][,x_coord] <- Info$xi[1]
        Agents[i,][,y_coord] <- Info$yi[1]
        
        #Now memory is updated. Time to update location on attitude space
        
        #First reset agent position to 0 before updating memory
        Agents$x[i] <- 0
        Agents$y[i] <- 0
        
        #Because the location of the agent is dependent on its memory, it will always be zero to begin with because almost all memories are "neutral". I need to average only over the non-zero memories.
        
        #Number of non-zero columns per agent a.k.a. how many memory spaces are filled + other variables
        
         nonZero <- sum(apply(Agents[i,], 2, function(c)sum(c!=0)))
         nonZero <- as.numeric(nonZero)
        
        # Averaging the x-values over the number of memories (of value x)
        Agents$x[i] <-  (sum(Agents[i,seq(10, ncol(Agents), 2)])/((nonZero-7)/2)) # -9 because there are always those 9 non memory columns which are nonZero, assuming that x and y are non zero.
        
        # Averaging the y-values over the number of memories (of value y)
        Agents$y[i] <- (sum(Agents[i,seq(11, ncol(Agents), 2)])/((nonZero-7)/2)) 
        
      } #Done integrating mainstream information 
      
      #Maybe put social networking here, after all agents have tried to integrate mainstream info
      
      #Determine the absolute valency of agent "opinion" (location)
      Agents$Valence[i] <- sqrt((Agents$x[i])^2 + (Agents$y[i])^2)
      
      #Turn Social_posting on/off
      if(Social_posting == TRUE){
      
      #For every agent, see if they reach over the sharing threshold. Agents with high sharing value will have an easier time breaching the threshold  and will share more often.
      if(Agents$Valence[i] < Agents$Share[i]){
        
        #If true, the agent will "post" it's location to members of it's group
        Info$xi[2] <- Agents$x[i]
        Info$yi[2] <- Agents$y[i]
        
        #Grab subset of agents who are in the same group as agent "i"
        #Find a way to have each person in social group integrate agent i's information. I already tried merging, but it gave an error. Keep trying!
        Social_group <- subset(Agents, Agents$Group == Agents$Group[i])
        
        #Removing agent "i" from subset, so he doesn't integrate his own information
        Social_group <- Social_group %>% 
          filter(AgentNo != i)
        
        #Loop through each agent in social group as they try to integrate the information
        for(s in 1:nrow(Social_group)){
          
          #Find the acceptance latitude of agent
          Latitude_social <- Social_group$Lat[s]
      
          #Find attitude sharpness of agent
          Sharpness_social <- Social_group$Sharpness[s]
          
          #distance between agent and social post
          #Maybe agents "i" will also integrate his own "new" information. But this is a bug for later.
          Distance_social <- sqrt( ((Social_group$x[s] - Info$xi[2])^2) + 
                                     ((Social_group$y[s] -   Info$yi[2])^2) )
          
           #Each agent tries to integrate
          #What is the chance they they will integrate
      RandNum_social <- runif(1,0,1)
      if (RandNum_social <
          Latitude_social^Sharpness_social/(Distance_social^Sharpness_social+Latitude_social^Sharpness_social)){
        
        # #If true, check if memory is full
         for(v in 10:ncol(Social_group)){
        
        #Check if memory slot is open
         if(Social_group[s,v] == 0){
        
           #If true, save the information to the empty memory space
           Social_group[s,v] <- Info$xi[2]
           Social_group[s,(v+1)] <- Info$yi[2]
           
           #Break out of loop and continue to next agent
           break
         }
        }
  
        #If full, sample memory space, and replace with new value (integrate)
        
        #which place in memory should the new info go
        
        #Sample which memory should be replaced. There are nMemo possible values
        sample_num <- as.character(sample(1:((ncol(Social_group)-9)/2), size=1))
        
        #Now i have the location (sample_num), I just need to plot in the new                   information
        colnames_df <- colnames(Social_group[s,])
       
        memory_to_replace <- as.data.frame(str_detect(colnames_df, sample_num))
        
        #Now I know the columns in which the new info should go. So I need to put it there
        column_social <- numeric()
        for(m in 1:nrow(memory_to_replace)){ #Two rows to loop through: memory x and y
          if(memory_to_replace[m,] == TRUE){
            
            column_social <- c(column_social, m) # Saving the index of the columns
            column_social <- as.list(column_social)
            
          }
        }
        x_coord <- column_social[[1]] # memory x coordinate column number
        y_coord <- column_social[[2]] # memory y coordinate column number
        
        #Reset agent position to 0 before updating memory
        Social_group$x[s] <- 0
        Social_group$y[s] <- 0
        
        # And now we save the new memory in the right location
        Social_group[s,][,x_coord] <- Info$xi[2]
        Social_group[s,][,y_coord] <- Info$yi[2]
        
        #Now memory is updated. Time to update location on attitude space
        
        #Because the location of the agent is dependent on its memory, it will always be zero to begin with because almost all memories are "neutral". I need to average only over the non-zero memories.
        
        #Number of non-zero columns per agent
        nonZero <- sum(apply(Social_group[s,], 2, function(c)sum(c!=0)))
        
        # Averaging the x-values over the number of memories (of value x)
        Social_group$x[s] <- sum(Social_group[s,seq(10, ncol(Social_group), 2)])/((nonZero-7)/2) # -7 because there are always those 7 non memory columns which are nonZero (at this place in the loop x and y are always zero)
        
        # Averaging the y-values over the number of memories (of value y)
        Social_group$y[s] <- sum(Social_group[s,seq(11, ncol(Social_group), 2)])/((nonZero-7)/2) 
        } #Done integrating
        #Merging doesn't work
      #Agents <- merge(Agents, Social_group, by = "AgentNo") 
      
      Agent_names <- Social_group$AgentNo
    for(x in Agent_names){
      
      #Check where the agent is in the original dataframe (AgentNo in Agents)
      if(Social_group$AgentNo[x] %in% Agents$AgentNo){
        #If true, replace old data new updated data
        Agents[x,] <- Social_group[x,]
    
          }
        } #Done updating (merging) dataframe
      } #Done looping through social group
      
      } # Valence > Share
    } # Social_posting == TRUE
  } # Done looping through agents
  
    #Visualization:
    if(t %% Plot_freq == 0 | t == 1){

    plot <- Agents %>%
    ggplot(aes(x, y, color = Group)) + geom_jitter(aes(size = Share)) + xlim(-1, 1) + ylim(-1, 1) +
      theme(legend.position = "None")

    print(plot)
    }
    
  }
  
  return(Agents)
 }

Agents2 <- GenPop(nPop = 500, nMemo = 16, Lat_accept = 0.3, Sharpness = 2, nGroups = 4)
#Where do the agents start the simulation (default (0,0))
Agents2[,2] <- runif(nrow(Agents2), -1, 1) #Random x coordinates
Agents2[,3] <- runif(nrow(Agents2), -1, 1) #Random y coordinates
Out1 <- ABM1(Agents = Agents2, Iterations = 500, Plot_freq = 10, Bias = "None", Social_posting = TRUE)
mean(Out1$x)
sd(Out1$x)
sd(Out1$y)


#For tomorrow: 
# 1. Find a way to model trustworthiness of information, 
# 2. figure out how Lorenz used information popularity, 
# 3. find a way to turn on social media, 
# 4. play with distributions of information valence (more likely positive/negative), 
# 5. see if I can visually see the confirmation bias that is modeled into the integration theory
# 6. Output??? Mean + sd of location over time?



```
  
 
```{r}
for(y in 1:20){
  
  if(y == 3){
    
    
    
    for(l in 1:10){
      
      if(l + y > 18){
        
        print("Ya dick")
        
        next
      }
    }
    }
}

Agents10 <- Agents
Agents10$`memory x1`[1] <- 0.5
Agents10$`memory y1`[1] <- 0.3

Agents10$`memory x1`[5] <- 0.5
Agents10$`memory y1`[5] <- 0.3

Social_group <- Agents10 %>% 
  filter(Group == Group[1])
Social_group$`memory x1`[1] <- 0.4234
Social_group$`memory y1`[1] <- 0.5345
column_names <- colnames(Agents)
new <- merge(Agents, Social_group, by = "AgentNo", all.x = T, incomparables = 0)

Agent_names <- Social_group$AgentNo
for(x in Agent_names){
  
  if(Social_group$AgentNo[x] %in% Agents10$AgentNo){
    #If true, replace old data new updated data
    Agents10[x,] <- Social_group[x,]
    
  }
}

```
 
 